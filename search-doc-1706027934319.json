{"searchDocs":[{"title":"Long Blog Post","type":0,"sectionRef":"#","url":"/blog/long-blog-post","content":"This is the summary of a very long blog post, Use a &lt;!-- truncate --&gt; comment to limit blog post size in the list view. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"MDX Blog Post","type":0,"sectionRef":"#","url":"/blog/mdx-blog-post","content":"Blog posts support Docusaurus Markdown features, such as MDX. tip Use the power of React to create interactive blog posts. &lt;button onClick={() =&gt; alert('button clicked!')}&gt;Click me!&lt;/button&gt; Click me!","keywords":"","version":null},{"title":"First Blog Post","type":0,"sectionRef":"#","url":"/blog/first-blog-post","content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet","keywords":"","version":null},{"title":"Welcome","type":0,"sectionRef":"#","url":"/blog/welcome","content":"Docusaurus blogging features are powered by the blog plugin. Simply add Markdown files (or folders) to the blog directory. Regular blog authors can be added to authors.yml. The blog post date can be extracted from filenames, such as: 2019-05-30-welcome.md2019-05-30-welcome/index.md A blog post folder can be convenient to co-locate blog post images: The blog supports tags as well! And if you don't want a blog: just delete this directory, and use blog: false in your Docusaurus config.","keywords":"","version":null},{"title":"API Key Authentication","type":0,"sectionRef":"#","url":"/docs/account-management/authentication-with-api-key","content":"API Key Authentication To ensure secure authorization for sending and receiving inferences in Semantix ML Hub, you need to create an API Key. Follow these steps to generate the correct authorization: 1. Navigate to Account Settings / API​ Start by signing in to your Semantix ML Hub account and navigating to the 'Account Settings / API' tab. 2. Create a New API Key​ Select 'Create New' to initiate the process of generating a new API Key. 3. Set Expiration Date​ Choose an expiration date for the API Key. This date determines how long the API Key will remain valid. Be sure to select an appropriate expiration date that aligns with your project's security requirements. 4. Create API Key​ After setting the expiration date, click on 'Create API Key' to generate the API Key. Your API Key is now created and ready for use. This key serves as your secure authentication token, allowing you to access and interact with Semantix ML Hub's APIs for sending and receiving inferences. Keep your API Key confidential and secure, as it provides access to your account's resources. By following these steps, you ensure the correct authorization and secure access to Semantix ML Hub's features and functionalities.","keywords":"","version":"Next"},{"title":"Overview","type":0,"sectionRef":"#","url":"/docs/automl/overview-automl","content":"","keywords":"","version":"Next"},{"title":"What is AutoML in Semantix ML Hub?​","type":1,"pageTitle":"Overview","url":"/docs/automl/overview-automl#what-is-automl-in-semantix-ml-hub","content":"AutoML, or Automated Machine Learning, is a feature that automates the process of training machine learning models. With Semantix ML Hub's AutoML, you can easily select features, set your target variable, define the task type, and specify metrics. Once configured, you simply press a button and wait for your model to be trained. ","version":"Next","tagName":"h2"},{"title":"Key Features​","type":1,"pageTitle":"Overview","url":"/docs/automl/overview-automl#key-features","content":"Feature Selection: Seamlessly pick and choose features from our feature store.Task Configuration: Specify whether you're working on a Classification or Regression task.Metrics Selection: Define the metrics that matter most to your model's performance.One-Click Training: With all parameters set, just press a button to start the training process.Results Review: Once training is complete, you can instantly view the results and performance of your model. ","version":"Next","tagName":"h2"},{"title":"Step-by-Step Guide to Using AutoML​","type":1,"pageTitle":"Overview","url":"/docs/automl/overview-automl#step-by-step-guide-to-using-automl","content":"AutoML Start Page: Start by clicking on the AutoML button on the bar in the left of the initial page. Click on Start New Job at the top of the page. Arrive at the Form page to pass the parameters of your AutoML job. Select Features: Select the Feature Table that you want to load data for training.Browse and select the features you want to include in your model.Click on 'Add to Model'. Configure Model: Set your target variable by selecting the relevant column name.Choose the type of task: 'Classification' or 'Regression'.Select the metrics you want to evaluate your model on, such as accuracy, precision, or RMSE. Start Training: Once you've configured your model, click on the 'Train Model' button.A progress bar will appear, showing the status of the training process. Review Results: After training is complete, navigate to the 'Results' tab.Here, you can view detailed metrics and performance indicators of your trained model. ","version":"Next","tagName":"h2"},{"title":"Conclusion​","type":1,"pageTitle":"Overview","url":"/docs/automl/overview-automl#conclusion","content":"AutoML in Semantix ML Hub is designed to make machine learning model development as straightforward and efficient as possible. Whether you're a beginner or an experienced data scientist, our platform provides the tools you need to develop and publish models with ease. Remember, if you prefer coding, Semantix ML Hub also offers a Python SDK for a more hands-on approach. Happy modeling! ss ","version":"Next","tagName":"h2"},{"title":"Auto Feature Selection","type":0,"sectionRef":"#","url":"/docs/automl/auto-feature-selection","content":"","keywords":"","version":"Next"},{"title":"Key Components​","type":1,"pageTitle":"Auto Feature Selection","url":"/docs/automl/auto-feature-selection#key-components","content":"Genetic Algorithm: Our system employs Genetic Algorithms, a powerful optimization technique inspired by the process of natural selection. Genetic Algorithms iteratively evolve a population of possible solutions to find the best feature subset. Task-Aware: The feature selection process is tailored to your task, whether it's classification or regression. This ensures that the chosen features are aligned with the objectives of your project. Scoring Function Guidance: You can customize the scoring function to match your specific requirements. The scoring function guides the Genetic Algorithm in selecting features that maximize model performance. Feature Count Control: Specify the number of features you want to include in your dataset. Our system will work to identify the optimal subset of features that meets your criteria. ","version":"Next","tagName":"h3"},{"title":"How It Works:​","type":1,"pageTitle":"Auto Feature Selection","url":"/docs/automl/auto-feature-selection#how-it-works","content":"Define Your Task: Begin by specifying whether you're working on a classification or regression task. Customize the Scoring Function: Tailor the scoring function to your project's goals. This function guides the Genetic Algorithm in evaluating feature subsets. Specify Feature Count: Indicate the desired number of features you want in your dataset. This is an essential criterion for feature selection. Genetic Algorithm Optimization: Our system uses Genetic Algorithms to explore different combinations of features. It evaluates each combination's performance based on your scoring function. Selection of Optimal Features: Through iterative optimization, the system identifies the subset of features that best maximizes model performance while adhering to your specified feature count. Feature Set Evaluation: Evaluate the chosen feature subset using various metrics and criteria to ensure that it meets your project's objectives. ","version":"Next","tagName":"h3"},{"title":"Benefits:​","type":1,"pageTitle":"Auto Feature Selection","url":"/docs/automl/auto-feature-selection#benefits","content":"Efficiency: Automate the feature selection process, saving time and effort in identifying the most relevant features for your model. Customization: Tailor the feature selection to your specific task and scoring function, ensuring that the selected features align with your project's goals. Performance Optimization: The Genetic Algorithm optimization process ensures that the chosen feature subset maximizes model performance. Objective-Driven: Select features based on the criteria that matter most to your project, whether it's classification or regression. Auto Feature Selection in Semantix ML Hub empowers you to make data-driven decisions by identifying the most valuable features for your machine learning tasks. This efficient and customizable process streamlines feature selection, allowing you to focus on building models with confidence. ","version":"Next","tagName":"h3"},{"title":"Training a Classifier Model","type":0,"sectionRef":"#","url":"/docs/automl/training-a-classifier-model","content":"","keywords":"","version":"Next"},{"title":"Key Components:​","type":1,"pageTitle":"Training a Classifier Model","url":"/docs/automl/training-a-classifier-model#key-components","content":"Automatic Pipeline Selection: Our platform automatically identifies the best pipeline, which includes data preprocessing steps and the machine learning model, tailored to your classification task. Auto Feature Selection: Feature selection is crucial for model performance. We employ Genetic Algorithms to efficiently select the most relevant features based on your specified scoring function and the desired number of features. Auto Balanced Dataset: If task is classification type, and to-balance is enabled, the AutoML will balance dataset as: Oversample when minority class that less 1%Undersample when minority class between 1% and 20% Auto Model Selection (TPOT): We leverage the TPOT package to find the best combination of preprocessing and machine learning models for your classification task. TPOT optimizes these combinations based on the scoring function you define. Results: AutoML provides various pieces of information when executed, including several metrics, training and testing datasets, pipeline DAG, and binary of the model. SDK Integration: We provide an SDK client that serves as a convenient wrapper for our backend API. This client enables you to run AutoML jobs, list job history, and access specific job details easily. ","version":"Next","tagName":"h3"},{"title":"Arguments Needed for Running an AutoML Job:​","type":1,"pageTitle":"Training a Classifier Model","url":"/docs/automl/training-a-classifier-model#arguments-needed-for-running-an-automl-job","content":"When running an AutoML job for classifier model training, you'll need to provide the following essential arguments: feature_table_name: The name of the feature table used for feature loading.target_name: The name of the target variable you want to predict.id_column: The name of the column containing unique identifiers in your dataframe.features_selected: A subset of features to select from the feature table.start_date: The date from which to load the features until the present date.end_date: The date until which to load the features.task: Specify that this is a classification task.scoring: Define the scoring function to use for evaluation. The scoring function may vary depending on your specific classification task.num_features: Specify the final number of features you want in the model.generations: The number of runs the Genetic Algorithm will perform before completing the optimization process.to-balance: If enabled and the task is of a classifier type, AutoML will utilize oversample and undersample methods to balance the dataset. ","version":"Next","tagName":"h3"},{"title":"Results:​","type":1,"pageTitle":"Training a Classifier Model","url":"/docs/automl/training-a-classifier-model#results","content":"The JSON result include: List of the features selectedMetrics to Train and Test Datasets: Accuracy, Balanced Accuracy, Confusion Matrix, f1, ks, precission, recall and ROC AUC. When multiclass, not calculate ROC AUC and Confusion Matrix Pipeline steps to inference PipelineDAG HTML Display the pipeline step in HTML format for visualization. Binary Model The binary model file is saved in pickle format. Train and Test Datasets. The datasets are in CSV format. ","version":"Next","tagName":"h3"},{"title":"Benefits:​","type":1,"pageTitle":"Training a Classifier Model","url":"/docs/automl/training-a-classifier-model#benefits","content":"Efficiency: Automate the entire process of classifier model development, from preprocessing to model selection, saving you time and effort. Customization: Tailor the feature selection, model selection, and scoring function to meet the unique requirements of your classification task. Performance Optimization: The system optimizes your pipeline, ensuring that it delivers the best possible results. Objective-Driven: Create classification models that align with your project's specific goals and metrics. Semantix ML Hub's AutoML for classifier models streamlines the process of building high-performing models for classification tasks. This integrated solution allows you to focus on extracting valuable insights from your data, knowing that your classification model is optimized for success. ","version":"Next","tagName":"h3"},{"title":"Training a Regression Model","type":0,"sectionRef":"#","url":"/docs/automl/training-a-regression-model","content":"","keywords":"","version":"Next"},{"title":"Key Components:​","type":1,"pageTitle":"Training a Regression Model","url":"/docs/automl/training-a-regression-model#key-components","content":"Automatic Pipeline Selection: Our platform automatically identifies the best pipeline, which includes data preprocessing steps and the machine learning model, tailored to your regression task. Auto Feature Selection: Feature selection is crucial for model performance. We employ Genetic Algorithms to efficiently select the most relevant features based on your specified scoring function and the desired number of features. Auto Model Selection (TPOT): We leverage the TPOT package to find the best combination of preprocessing and machine learning models for your regression task. TPOT optimizes these combinations based on the scoring function you define. SDK Integration: We provide an SDK client that serves as a convenient wrapper for our backend API. This client enables you to run AutoML jobs, list job history, and access specific job details easily. ","version":"Next","tagName":"h3"},{"title":"Arguments Needed for Running an AutoML Job:​","type":1,"pageTitle":"Training a Regression Model","url":"/docs/automl/training-a-regression-model#arguments-needed-for-running-an-automl-job","content":"When running an AutoML job for regression model training, you'll need to provide the following essential arguments: feature_table_name: The name of the feature table used for feature loading.target_name: The name of the target variable you want to predict.id_column: The name of the column containing unique identifiers in your dataframe.features_selected: A subset of features to select from the feature table.start_date: The date from which to load the features until the present date.end_date: The date until which to load the features.task: Specify that this is a regression task.scoring: Define the scoring function to use for evaluation. The scoring function may vary depending on your specific regression task.num_features: Specify the final number of features you want in the model.generations: The number of runs the Genetic Algorithm will perform before completing the optimization process. ","version":"Next","tagName":"h3"},{"title":"Benefits:​","type":1,"pageTitle":"Training a Regression Model","url":"/docs/automl/training-a-regression-model#benefits","content":"Efficiency: Automate the entire process of regression model development, from preprocessing to model selection, saving you time and effort. Customization: Tailor the feature selection, model selection, and scoring function to meet the unique requirements of your regression task. Performance Optimization: The system optimizes your pipeline, ensuring that it delivers the best possible results for regression. Objective-Driven: Create regression models that align with your project's specific goals and metrics. Semantix ML Hub's AutoML for regression models streamlines the process of building high-performing models for regression tasks. This integrated solution allows you to focus on extracting valuable insights from your data, knowing that your regression model is optimized for success. ","version":"Next","tagName":"h3"},{"title":"Using AutoML via the SDK","type":0,"sectionRef":"#","url":"/docs/automl/using-automl-via-the-sdk","content":"","keywords":"","version":"Next"},{"title":"Key Features:​","type":1,"pageTitle":"Using AutoML via the SDK","url":"/docs/automl/using-automl-via-the-sdk#key-features","content":"Run AutoML Jobs: The SDK allows you to initiate and execute AutoML jobs effortlessly. You can define your job parameters, including the feature table, target variable, and other essential settings. List Job History: Gain visibility into your past AutoML jobs. The SDK enables you to view a list of all the jobs you've executed, providing valuable insights into your workflow. Retrieve Job Details: Access specific job details for in-depth analysis. You can retrieve information about a particular job, including its status, results, and configuration. Retrieve Job outputs: Retrieve both the trained model and model metadata directly from our storage using specific sdk methods. ","version":"Next","tagName":"h3"},{"title":"How to Use the SDK:​","type":1,"pageTitle":"Using AutoML via the SDK","url":"/docs/automl/using-automl-via-the-sdk#how-to-use-the-sdk","content":"To utilize the SDK effectively, you can perform the following actions: Authentication: Set the MLHUB_API_KEY as environment variable, by using: os.environ[&quot;MLHUB_API_KEY&quot;] = ADD YOUR API KEY HERE%env MLHUB_API_KEY = ADD YOUR API KEY HERE (Jupyter notebook) AutoML SDK Client: Instantiate our Client by passing the environment that you want to work on. from elemeno_ai_sdk.ml.automl.client import AutoMLClient client = AutoMLClient(env=env) The variable env must be dev or prod. Run an AutoML Job: Use the SDK to define the parameters for your AutoML job, including the feature table, target variable, task type (classification or regression), scoring function, and more. The SDK will handle the execution of the job on our platform. result = await client.run_job( feature_table_name=FEATURE_TABLE_NAME, features_selected=FEATURES_SELECTED, id_column=ID_COLUMN, target_name=TARGET_NAME, start_date=START_DATE, end_date=END_DATE, task=TASK, scoring=SCORING, num_features=NUM_FEATURES, generations=GENERATIONS, to_balance=TO_BALANCE ) The result of this command is just the id of the job. {&quot;id&quot;:&quot;65395ed4506bc9b4b418f29a&quot;}  List Job History: Access a comprehensive list of all the AutoML jobs you've previously executed. This feature provides a historical overview of your modeling efforts. It works by running: job_list = await client.list_jobs() The result of the previous command is just a list of all historical jobs with the status and the job params: {'resources': [ {'id': '652eba92dc623bcd5e5f4cb6', 'featureTableName': 'feature_table_name_1', 'generations': 1, 'idColumn': 'id', 'status': 'RUNNING', 'targetName': 'is_over30mob3', 'startDate': '2022-01-01 00:00:00 +0000 UTC', 'updatedAt': '2023-10-17 16:47:14.289 +0000 UTC', 'endDate': '2023-10-13 00:00:00 +0000 UTC', 'task': 'classification', 'scoring': 'ks', 'numFeatures': 4, 'createdAt': '2023-10-17 16:47:14.289 +0000 UTC'}, {'id': '652d6c53dc623bcd5e5f4caa', 'featureTableName': 'feature_table_name_2', 'generations': 1, 'idColumn': 'id', 'status': 'RUNNING', 'targetName': 'target', 'startDate': '2022-01-01 00:00:00 +0000 UTC', 'updatedAt': '2023-10-16 17:01:07.361 +0000 UTC', 'endDate': '2023-10-13 00:00:00 +0000 UTC', 'task': 'classification', 'scoring': 'ks', 'numFeatures': 2, 'createdAt': '2023-10-16 17:01:07.361 +0000 UTC'}, {'id': '652d6bc4dc623bcd5e5f4ca9', 'featureTableName': 'feature_table_name_3', 'generations': 1, 'idColumn': 'id', 'status': 'FINISHED', 'targetName': 'is_over30mob3', 'startDate': '2022-01-01 00:00:00 +0000 UTC', 'updatedAt': '2023-10-16 16:58:44.222 +0000 UTC', 'endDate': '2023-10-11 00:00:00 +0000 UTC', 'task': 'classification', 'scoring': 'ks', 'numFeatures': 3, 'createdAt': '2023-10-16 16:58:44.222 +0000 UTC'}, ...] } Retrieve Job Details: Dive deeper into a specific AutoML job by retrieving its details. Just run: job = await client.get_job(job_id=job_id) Where the job_id you get when you run the job using the run_job method. The result of this command is all the information of this respective job id, with the current job status and a uri to retrieve the output of the AutoML job like the trained model and it's metadata. { 'id': '651ec3562e0e8d99b6006597', 'featureTableName': 'creditcard_demo', 'generations': 1, 'idColumn': 'id', 'status': 'RUNNING', 'artifactUri': 's3://mlflow/188/f59665c5609d48b9a622bf60c463b377/artifacts', 'targetName': 'class', 'startDate': '2023-01-01', 'endDate': '2023-10-02', 'task': 'classification', 'scoring': 'ks', 'numFeatures': 5 } Retrieve Job outputs: Acess both the model trained and model metadata using two distinct method from our AutoML client. Trained Model: This method will download the pickle of the trained model outputed by the job is with this job_id with the name model.pkl await client.get_model(job_id=job_id) and them you can load it by using the pickle library. model = pickle.load(open(&quot;./model.pkl&quot;, &quot;rb&quot;)) Model Metadata: The model metadata is a json that contains some informations about the trained model, such as used features, model metrics and parameters of the pipeline steps. response = await client.get_metadata(job_id=job_id) And the response is { &quot;features&quot;: [ &quot;v1&quot;, &quot;v2&quot;, &quot;v3&quot;, &quot;v4&quot;, &quot;v10&quot; ], &quot;metrics&quot;: { &quot;accuracy&quot;: 0.9753333333333334, &quot;balancedAccuracy&quot;: 0.9751315955662212, &quot;confusionMatrix&quot;: { &quot;falseNegatives&quot;: 24, &quot;falsePositives&quot;: 13, &quot;trueNegatives&quot;: 756, &quot;truePositives&quot;: 707 }, &quot;f1&quot;: { &quot;class0&quot;: 0.9761136216914138, &quot;class1&quot;: 0.974500344589938 }, &quot;ks&quot;: 0.9502631911324423, &quot;precision&quot;: { &quot;class0&quot;: 0.9692307692307692, &quot;class1&quot;: 0.9819444444444444 }, &quot;recall&quot;: { &quot;class0&quot;: 0.9830949284785435, &quot;class1&quot;: 0.9671682626538988 }, &quot;rocAuc&quot;: 0.9751315955662211 }, &quot;pipelineSteps&quot;: [ { &quot;name&quot;: &quot;polynomialfeatures&quot;, &quot;params&quot;: { &quot;degree&quot;: 2, &quot;includeBias&quot;: false, &quot;interactionOnly&quot;: false, &quot;order&quot;: &quot;C&quot; } }, { &quot;name&quot;: &quot;gradientboostingclassifier&quot;, &quot;params&quot;: { &quot;degree&quot;: 0, &quot;includeBias&quot;: false, &quot;interactionOnly&quot;: false, &quot;order&quot;: &quot;&quot; } } ], &quot;target&quot;: [ 0, 1 ] }  By utilizing the SDK, you streamline your interaction with Semantix ML Hub's AutoML capabilities. It's a powerful tool that empowers you to manage your machine learning tasks efficiently, from job initiation to result analysis. Whether you're a data scientist looking to automate your model development process or an AI enthusiast exploring the possibilities of AutoML, our SDK simplifies the experience, allowing you to focus on deriving valuable insights from your data. ","version":"Next","tagName":"h3"},{"title":"Ingesting Features from a CSV","type":0,"sectionRef":"#","url":"/docs/feature-store/ingestion-data/ingesting-features-from-a-csv-file","content":"Ingesting Features from a CSV In Semantix ML Hub, you can conveniently ingest features from a CSV dataset, making it a seamless process to work with your data. Follow these steps to upload a CSV dataset and select features based on the data provided: 1. Upload the CSV Dataset Begin by navigating to the Data Connectors section within Semantix ML Hub.Select &quot;Add New&quot; to start the process of ingesting features from your CSV dataset.Upload your CSV file by either dragging and dropping it or selecting it from your local file system. 2. Create Feature Table Now, you can proceed with selecting the features you want to use from the CSV dataset. Features are the specific attributes or columns of your data that are relevant to your machine learning task. check this page. By following these steps, you can effortlessly ingest features from a CSV dataset into Semantix ML Hub. This feature-rich platform streamlines the process of working with your data, enabling you to focus on developing machine learning models and deriving valuable insights from your data. With your features now available, you can proceed with creating feature tables and building your machine learning projects.","keywords":"","version":"Next"},{"title":"Feature Store","type":0,"sectionRef":"#","url":"/docs/feature-store/overview","content":"","keywords":"","version":"Next"},{"title":"Table of Contents​","type":1,"pageTitle":"Feature Store","url":"/docs/feature-store/overview#table-of-contents","content":"Creating a Feature TableIngesting Features From a CSVIngesting Features With the Python SDKIngesting Features From a Pipeline ToolObtaining Features For Training a ModelObtaining Features at Inference TimeWorking With Binary Features (Images) ","version":"Next","tagName":"h3"},{"title":"Version​","type":1,"pageTitle":"Feature Store","url":"/docs/feature-store/overview#version","content":"elemeno-ai-sdk: 0.6.15 ","version":"Next","tagName":"h3"},{"title":"Working with Binary Features (Images)","type":0,"sectionRef":"#","url":"/docs/feature-store/working-with-binary-features-images","content":"","keywords":"","version":"Next"},{"title":"Automatic Image Handling:​","type":1,"pageTitle":"Working with Binary Features (Images)","url":"/docs/feature-store/working-with-binary-features-images#automatic-image-handling","content":"DataFrame Schema Analysis: When you define a dataframe schema, Semantix ML Hub's system automatically analyzes it to identify any binary features that contain image data. Image Detection: Our system recognizes binary features that represent images based on their data type and structure within the schema. Image Download and Storage: Upon detecting image data, our SDK takes care of downloading and saving these images, ensuring that they are readily accessible for further analysis or processing. ","version":"Next","tagName":"h3"},{"title":"Benefits:​","type":1,"pageTitle":"Working with Binary Features (Images)","url":"/docs/feature-store/working-with-binary-features-images#benefits","content":"Effortless Image Integration: You don't need to worry about manually handling image data within your dataframes. Our system automatically identifies and manages image features, simplifying the data preparation process. Image Accessibility: The downloaded images are easily accessible through our SDK, allowing you to access and work with them as needed for your machine learning tasks. Streamlined Workflow: By automating the handling of binary features like images, Semantix ML Hub enhances the efficiency of your data science workflow, enabling you to focus on building and training your machine learning models. Working with binary features, especially images, becomes a seamless part of your data preparation and analysis process within Semantix ML Hub. Our system's automatic recognition and management of image data ensure that you can leverage image features effortlessly in your machine learning projects. ","version":"Next","tagName":"h3"},{"title":"Ingesting Features From a Pipeline Tool","type":0,"sectionRef":"#","url":"/docs/feature-store/ingestion-data/ingesting-features-from-a-pipeline","content":"Ingesting Features From a Pipeline Tool In Semantix ML Hub, we offer flexibility in ingesting features into our feature store, allowing you to seamlessly integrate data from your preferred pipeline tools. Here's how you can ingest features from a pipeline tool: Utilize Your Pipeline Tool: First, use your preferred pipeline tool to create a dataframe containing the relevant features for your machine learning project. This pipeline tool can be any software or system you prefer to work with, ensuring that it aligns with your data processing needs. Integration with Our SDK: Once you have your dataframe with features ready, leverage our Software Development Kit (SDK) to ingest this data into our feature store. Our SDK serves as a powerful tool for interacting with Semantix ML Hub's features and capabilities. Ingest Data: Using the SDK, you can initiate the ingestion process, transferring the data from your pipeline tool's dataframe into our feature store seamlessly. The SDK provides the necessary functions and methods to facilitate this integration effortlessly. By following these steps, you can efficiently incorporate features from your pipeline tool into our feature store, ensuring that your data is readily available for training machine learning models, conducting analyses, and driving insights. This seamless integration enhances your data science workflow, allowing you to make the most of Semantix ML Hub's feature management capabilities.","keywords":"","version":"Next"},{"title":"Creating a Feature Table","type":0,"sectionRef":"#","url":"/docs/feature-store/creating-a-feature-table","content":"Creating a Feature Table In Semantix ML Hub, creating a Feature Table is a fundamental step in organizing and managing your data for machine learning. This guide will walk you through the process of creating a Feature Table. Follow these steps to get started: 1. Name Your Feature Table Start by giving your Feature Table a meaningful name that reflects the purpose or content of the table. This name will help you identify and locate your Feature Table easily within the platform. 2. Define Your Business Entities Business Entities are critical components of your Feature Table, as they define how data is organized and linked. For each Business Entity, specify the following: Entity Name: Provide a name that represents the type of entity, such as &quot;Customer&quot; or &quot;Product.&quot;Identifier: Define an identifier for the entity. This identifier is used to uniquely identify records within the entity.Type: Indicate the data type of the identifier, which could be string, integer, float, or another appropriate type. 3. Define Your Feature Collection Features are the data attributes or characteristics that you want to include in your Feature Table. For each feature, provide the following information: Feature Name: Name your feature descriptively to convey its purpose or content.Type: Specify the data type of the feature, such as integer, float, or categorical.Add more Features if necessary: Depending on your project requirements, add all the relevant features to the Feature Table. 4. Create Your Feature Table After you have defined your Business Entities and Feature Collection, it's time to create your Feature Table. Click the &quot;Create&quot; button to finalize the Feature Table creation process. By following these steps, you'll have successfully created a Feature Table in Semantix ML Hub. This Feature Table will serve as a structured repository for your data assets, making it easier to manage and utilize features for machine learning tasks. Now that you have your Feature Table ready, you can proceed with ingesting data and working with features for your projects.","keywords":"","version":"Next"},{"title":"Create a Financial Risk Predictor","type":0,"sectionRef":"#","url":"/docs/getting-started/create-a-financial-risk-predictor","content":"","keywords":"","version":"Next"},{"title":"","type":1,"pageTitle":"Create a Financial Risk Predictor","url":"/docs/getting-started/create-a-financial-risk-predictor##","content":"In this guide, we will walk you through the process of using Semantix ML Hub to create a Financial Risk Predictor. This tool empowers you to build, deploy, and use a machine learning model for predicting financial risk, making data-driven decisions about loan defaults. Follow these step-by-step instructions to get started: 1. Download the CSV Please download the following dataset:financial_risk_dataset.csv 2. Add a Data Connector Go to the Data Connectors section within Semantix ML Hub.Select &quot;Add New.&quot;Upload the CSV file you downloaded in step 1.Provide a name for the data connector. 3. Create a Feature Table Navigate to the Feature Tables page.Click on &quot;Create Feature Table&quot;Give your feature table a name.Select the CSV file used in the Data Connectors page. 4. Define Business Entity Using only normal characters and numbers, name your Business Entity.Select 'index' as the Identifier and 'string' as the Type. 5. Add Features to the Feature Table Click on &quot;Add Feature.&quot;Add the following three features with their respective types: feature: employed , type: integerfeature: bank_balance , type: floatfeature:annual_salary , type: float 6. Create the Feature Table Click &quot;Create&quot; to create the Feature Table.Please wait until the Feature Table finishes deploying before moving onto the next step. You will know that the Feature Table is fully deployed when the status turns green. 7. Set Up the Inference Server After the Feature Table is fully deployed, go to the Inference Servers tab. Select &quot;Add Inference Server.&quot; Name your Inference Server. Choose &quot;ONNX&quot; as the framework. Upload the default_model_1.onnx file (provided).default_model_1.onnx Configure your Request Body by adding 'index' as your REQUEST_BODY_KEY. Add the 3 features used when setting up your Feature Table. In the left column, select the dataset that was previously uploaded. In the right column, select the 3 features: employed, bank_balance, and annual_salary. 8. Wait for Inference Server Allocation Your Inference Server is now created, but please allow a few minutes for your server to be fully deployed. . You can use this time to discuss other aspects of your project, or to generate an API Key. 9. Generate an API Key Head over to the Account Settings / API tab.Select &quot;Create New&quot;Adjust the expiration date to your preferred date and select 'Create API Key'. 10. Send an Inference Return to the Inference Server tab and make sure your server is deployed by viewing the Status. Once fully deployed, the status will turn green and you can move on to the next step. Copy your Inference Server's API Endpoint. Use a tool that works as an API platform, provide your endpoint, API Key, and use the following JSON command to send a POST request: { &quot;index&quot;: &quot;2&quot; }  11. Inference Results After running the command, you will receive a confidence level indicating how likely the employee is to default on a loan. Follow these steps meticulously to create your Financial Risk Predictor using Semantix ML Hub. This tool empowers you to make informed financial decisions based on machine learning predictions. ","version":"Next","tagName":"h2"},{"title":"Obtaining Features at Inference Time","type":0,"sectionRef":"#","url":"/docs/feature-store/obtaining-features/obtaining-features-at-inference-time","content":"","keywords":"","version":"Next"},{"title":"Method Signature:​","type":1,"pageTitle":"Obtaining Features at Inference Time","url":"/docs/feature-store/obtaining-features/obtaining-features-at-inference-time#method-signature","content":"get_online_features(self, feature_table_name: str, entities: Dict[str, List], features: List[str])  ","version":"Next","tagName":"h3"},{"title":"Method Parameters:​","type":1,"pageTitle":"Obtaining Features at Inference Time","url":"/docs/feature-store/obtaining-features/obtaining-features-at-inference-time#method-parameters","content":"feature_table_name (str): The name of the feature view from which you want to retrieve features. entities (Dict): A dict of entities for which you want to retrieve features. Entities represent the specific instances or entities for which you need feature values. features (list or None): An optional list of features you wish to retrieve. If set to None, all available features will be retrieved for the specified entities. ","version":"Next","tagName":"h3"},{"title":"Output:​","type":1,"pageTitle":"Obtaining Features at Inference Time","url":"/docs/feature-store/obtaining-features/obtaining-features-at-inference-time#output","content":"The get_online_features method outputs the most recent versions of the requested features for the specified entities. These features are ready to be used for real-time inference, allowing you to make predictions and decisions based on the latest data. By using this SDK method, you can easily access the features required for online inference, ensuring that your models receive up-to-date and relevant data for making accurate predictions in real-time scenarios. Semantix ML Hub simplifies the process of obtaining features during inference, enhancing the efficiency and effectiveness of your machine learning applications. ","version":"Next","tagName":"h3"},{"title":"Getting Started with Semantix ML Hub","type":0,"sectionRef":"#","url":"/docs/getting-started/first-steps","content":"","keywords":"","version":"Next"},{"title":"","type":1,"pageTitle":"Getting Started with Semantix ML Hub","url":"/docs/getting-started/first-steps##","content":"Welcome to Semantix ML Hub! This guide will help you get started with the basic workflow for building, deploying, and managing machine learning models with our platform. ","version":"Next","tagName":"h2"},{"title":"Signing Up​","type":1,"pageTitle":"Getting Started with Semantix ML Hub","url":"/docs/getting-started/first-steps#signing-up","content":"First, you'll need to sign up for a Semantix ML Hub account. You can sign up on our website at https://home.ml.semantixhub.com. Once you've entered your information and confirmed your email, you'll have access to the ML Hub. ","version":"Next","tagName":"h3"},{"title":"Creating Your First Project​","type":1,"pageTitle":"Getting Started with Semantix ML Hub","url":"/docs/getting-started/first-steps#creating-your-first-project","content":"After logging in, you'll be taken to the Data Connectors page. Here you can connect to an external source of data or upload a simple CSV (not recommended for production use cases). To create a connection, click the button with the type of Data Connector you desire to use or on the &quot;Add New&quot; button on the top of the page. Provide the necessary information for configuring the connection and complete by clicking in &quot;Add Data Connector&quot;. You can look at our documentation for learning how to build an ingestion integration with your preferred data pipeline management tool. Once your data connector is created, you'll be taken to the feature table page so that you can start configuring your feature store. ","version":"Next","tagName":"h3"},{"title":"Obtaining Features for Training a Model","type":0,"sectionRef":"#","url":"/docs/feature-store/obtaining-features/obtaining-features-for-training-a-model","content":"","keywords":"","version":"Next"},{"title":"Method Signature:​","type":1,"pageTitle":"Obtaining Features for Training a Model","url":"/docs/feature-store/obtaining-features/obtaining-features-for-training-a-model#method-signature","content":"get_training_features( self, feature_table_name: str, entities: List[str] = None, features: List[str] = None, date_from: Optional[str] = None, date_to: Optional[str] = None, ) -&gt; pd.DataFrame  ","version":"Next","tagName":"h3"},{"title":"Method Parameters:​","type":1,"pageTitle":"Obtaining Features for Training a Model","url":"/docs/feature-store/obtaining-features/obtaining-features-for-training-a-model#method-parameters","content":"feature_table_name (str): The name of the feature view from which you want to retrieve features. entities (list or None): A list of entities fields you want to select. If set to None, all entities fields will be selected. features (list or None): A list of features you want to select. If set to None, all available features will be selected. date_from (str or None): The start date of the training period. If set to None, the start date of the feature table will be used. date_to (str or None): The end date of the training period. If set to None, the end date of the feature table will be used. ","version":"Next","tagName":"h3"},{"title":"Output:​","type":1,"pageTitle":"Obtaining Features for Training a Model","url":"/docs/feature-store/obtaining-features/obtaining-features-for-training-a-model#output","content":"The get_training_features method outputs a pandas DataFrame containing all the selected features. You can use this DataFrame for training your machine learning models with the relevant training data. By leveraging this SDK method, you can effortlessly obtain the features you need for your model training, making it a convenient and efficient process within Semantix ML Hub. ","version":"Next","tagName":"h3"},{"title":"Concepts","type":0,"sectionRef":"#","url":"/docs/getting-started/concepts","content":"","keywords":"","version":"Next"},{"title":"","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts##","content":"In this section, we will explore fundamental machine learning concepts used within Semantix ML Hub. These concepts are essential for understanding and effectively utilizing our platform. Whether you're a seasoned data scientist or new to the field, this documentation will serve as a valuable reference. ","version":"Next","tagName":"h2"},{"title":"Machine Learning Concepts​","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts#machine-learning-concepts","content":"","version":"Next","tagName":"h2"},{"title":"1. Feature Store​","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts#1-feature-store","content":"The Feature Store is a fundamental component of machine learning development within Semantix ML Hub. It serves as a centralized repository for managing and organizing your data-related assets, enabling you to streamline the feature engineering process and enhance your machine learning models. 1.1 Data Connector​ Data Connectors are integral to the Feature Store's functionality. They establish connections to various data sources, allowing you to seamlessly import and integrate data into your ML workflows. Whether your data resides in databases, data lakes, or external APIs, Data Connectors simplify the data ingestion process. To work with Data Connectors, follow these steps: Create a Data Connector: Start by defining a Data Connector that specifies the source of your data. Configure the connection parameters, such as database credentials or API endpoints. Data Ingestion: Use the configured Data Connector to import data into your Feature Store. This can include structured data, time series data, or unstructured data, depending on your project requirements. Data Transformation: Once the data is ingested, you can perform data transformation operations as needed. This might include data cleaning, feature extraction, or data enrichment. 1.2 Feature​ In the context of the Feature Store, a Feature represents a specific data attribute or characteristic that you want to use for machine learning. Features can be numerical, categorical, or text-based, and they play a crucial role in training machine learning models. Key actions related to Features include: Feature Definition: Define and describe each Feature within the Feature Store. This includes specifying the data type, source, and any relevant metadata. Feature Versioning: Track the evolution of Features over time. Versioning ensures that you can reproduce results and maintain consistency in your ML pipelines. 1.3 Feature Engineering​ Feature Engineering is the process of creating new Features or modifying existing ones to improve the performance of machine learning models. The Feature Store provides tools and capabilities to facilitate this essential step in the ML lifecycle. Feature Engineering tasks often include: Feature Transformation: Apply mathematical operations or statistical transformations to Features to make them more informative or suitable for modeling. Feature Aggregation: Create aggregated Features from raw data, such as computing statistics over time windows. Feature Selection: Identify the most relevant Features for your specific machine learning task. The Feature Store assists in assessing Feature importance. 1.4 Feature Table​ A Feature Table is a structured collection of Features organized for a particular machine learning use case. It simplifies the process of accessing and utilizing Features within your ML projects. Here's how Feature Tables work: Create a Feature Table: Define a Feature Table that encapsulates the Features relevant to your ML model. You can select Features from the Feature Store to include in the table. Versioned Feature Tables: Similar to individual Features, Feature Tables support versioning. You can track changes and updates to the Feature Table's content. By understanding these core concepts within the Feature Store, you'll be better equipped to efficiently manage your data assets and drive the success of your machine learning projects. Next, we'll delve into other essential machine learning concepts. ","version":"Next","tagName":"h3"},{"title":"2. Models​","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts#2-models","content":"In the world of machine learning, Models are at the heart of predictive and decision-making tasks. Semantix ML Hub empowers you to build, deploy, and manage machine learning models seamlessly. Let's explore the key sub-concepts related to Models. 2.1 Model Binary​ A Model Binary is the serialized and trained machine learning model, typically stored in a file format. This binary encapsulates the model's architecture, learned parameters, and associated metadata. In Semantix ML Hub, you can work with Model Binaries for various purposes: Model Serialization: Save trained machine learning models as Model Binaries for later use. This enables you to avoid retraining models from scratch. Model Versioning: Manage different versions of your models by storing their corresponding Model Binaries. Versioning ensures reproducibility and tracking of model changes over time. Model Deployment: Deploy Model Binaries into production environments, making your models available for real-time predictions and decision-making. 2.2 Hyper-parameters​ Hyper-parameters are configuration settings that govern the training process of a machine learning model. They are not learned from the data but are predefined by the data scientist or ML engineer. Understanding and tuning hyper-parameters is crucial for model performance optimization. Here are key aspects of hyper-parameters: Hyper-parameter Selection: Choose appropriate hyper-parameter values based on your specific machine learning task and dataset. This selection can significantly impact model performance. Hyper-parameter Tuning: Semantix ML Hub provides tools and utilities for hyper-parameter tuning, allowing you to systematically explore different configurations and find the best set of hyper-parameters for your model. 2.3 Metrics​ Metrics are quantitative measures used to evaluate the performance of machine learning models. These measures provide insights into how well a model is performing its intended task. In Semantix ML Hub, you can track and analyze various metrics to assess model quality. Commonly used metrics include: Accuracy: Measures the overall correctness of model predictions. Precision and Recall: Evaluate the model's ability to make correct positive predictions and capture all true positives, respectively. F1-Score: A harmonic mean of precision and recall, useful for imbalanced datasets. Mean Absolute Error (MAE) and Mean Squared Error (MSE): Metrics for regression tasks, quantifying prediction errors. Area Under the Receiver Operating Characteristic Curve (AUC-ROC): Assess the model's ability to distinguish between classes in binary classification problems. By comprehending these sub-concepts within the Models category, you'll be better equipped to work with machine learning models effectively in Semantix ML Hub. Next, we'll delve into additional machine learning concepts to enhance your understanding of our platform's capabilities. ","version":"Next","tagName":"h3"},{"title":"3. Model Registry​","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts#3-model-registry","content":"The Model Registry is a pivotal component of Semantix ML Hub, designed for the systematic management and versioning of machine learning models. This specialized section of the Registry is dedicated to ensuring the reliability and scalability of your machine learning projects. Let's explore the core functionalities of the Model Registry: 3.1 Model Versioning​ Model Versioning is at the heart of the Model Registry. It allows you to maintain multiple versions of your machine learning models, complete with associated artifacts and hyper-parameters. This versioning serves several critical purposes: Reproducibility: Ensure that you can reproduce and re-deploy previous versions of your models, which is essential for maintaining consistency in your ML workflows. Comparison and Selection: Easily compare the performance of different model versions to select the most suitable one for your specific task. Auditing and Compliance: Keep track of model changes and the individuals responsible for those changes, facilitating auditing and compliance requirements. 3.2 Model Metadata​ The Model Registry also offers a platform for rich Model Metadata management. You can store comprehensive information about each model, including: Purpose: Describe the intended use case and objectives of the model. Training Data Sources: Document the datasets used to train the model, enhancing transparency and data lineage. 3.3 Model Deployment​ Once you've perfected your machine learning model and stored it in the Model Registry, Semantix ML Hub makes it effortless to deploy your models into production environments. This streamlined Model Deployment process ensures that your models are readily available for real-time inference and decision-making. By harnessing the capabilities of the Model Registry, you can confidently manage your machine learning models, maintain version control, and seamlessly transition from development to production with ease. This central hub for model governance empowers you to unlock the full potential of MLOps within Semantix ML Hub. ","version":"Next","tagName":"h3"},{"title":"4. Inference Server​","type":1,"pageTitle":"Concepts","url":"/docs/getting-started/concepts#4-inference-server","content":"The Inference Server is a critical component within Semantix ML Hub that facilitates the deployment and execution of machine learning models in production environments. It serves as the bridge between your trained models and real-time inference, enabling you to make predictions and decisions based on your ML models. Let's explore the key functionalities of the Inference Server: 4.1 Model Deployment​ The primary role of the Inference Server is to manage the Model Deployment process. It ensures that your trained machine learning models are readily available for inference tasks in production. Key aspects of model deployment include: Model Selection: Choose the specific version of your model from the Model Registry for deployment. This versioning allows you to ensure consistency in production. Scalability: Scale your model deployments horizontally to handle varying levels of inference requests, ensuring responsiveness and reliability. Concurrency Control: Manage multiple inference requests concurrently while maintaining efficient resource utilization. 4.2 RESTful API​ The Inference Server exposes a RESTful API that serves as the interface for interacting with deployed machine learning models. This API allows you to send data for inference and receive predictions as responses. Important features of the API include: Endpoint Configuration: Define API endpoints for each deployed model, specifying the input and output data formats. Authentication and Security: Secure the API endpoints with authentication mechanisms to control access and protect sensitive data. Logging and Monitoring: Monitor API performance and log inference requests and responses for auditing and troubleshooting. 4.3 Real-time Inference​ With the Inference Server, you can perform Real-time Inference on data as it arrives, making instantaneous predictions and decisions based on your machine learning models. This capability is essential for a wide range of applications, including fraud detection, recommendation systems, and image recognition. Low Latency: Achieve low inference latency, ensuring that predictions are made within milliseconds, ideal for real-time applications. Batch Inference: In addition to real-time inference, the Inference Server supports batch processing for large-scale data. Model Monitoring: Continuously monitor the performance of deployed models to detect deviations and ensure the quality of predictions over time. By harnessing the power of the Inference Server within Semantix ML Hub, you can seamlessly transition from model development to production, providing real-time insights and automation through your machine learning models. This concept is integral to MLOps, allowing you to deploy and maintain ML solutions effectively. ","version":"Next","tagName":"h3"},{"title":"Serving Models - Overview","type":0,"sectionRef":"#","url":"/docs/serving-models/overview-2","content":"","keywords":"","version":"Next"},{"title":"Key Features:​","type":1,"pageTitle":"Serving Models - Overview","url":"/docs/serving-models/overview-2#key-features","content":"Model Selection: You have the flexibility to define a unique model identifier, making it easy to manage and identify different models. Model Frameworks: Our platform supports a wide range of popular model frameworks, including Scikit-learn, PyTorch, TensorFlow, TensorFlow Lite, Keras, and ONNX. This ensures compatibility with your preferred machine learning frameworks. Model Upload: You can upload your trained model file, whether it's a pickled model or a .pt model, to our platform for deployment. Request Structure Definition: Define how you want the inference server to receive requests, ensuring that it aligns with your specific use case. You have multiple options: Utilize a feature table: All the necessary features for inference are preloaded into a feature table. You only need to pass the business ID defined in the feature table when making a request.Send JSON requests: You can send JSON data with all the required features for inference at the time of the request.Combine the above methods: Customize your request structure by using a combination of feature tables and JSON requests to meet your unique needs. ","version":"Next","tagName":"h3"},{"title":"Benefits:​","type":1,"pageTitle":"Serving Models - Overview","url":"/docs/serving-models/overview-2#benefits","content":"Easy Deployment: Deploying your machine learning models as inference servers is a straightforward process, allowing you to quickly put your models into production. Framework Compatibility: Our platform supports a variety of popular machine learning frameworks, ensuring that you can deploy models trained with your preferred tools. Flexible Request Handling: Define the request structure that best suits your use case, whether it involves feature tables, JSON data, or a combination of both. Scalability: Serve models at scale by utilizing HTTP requests, making it easy to handle predictions for a large number of requests from your applications or services. Semantix ML Hub's model serving capabilities simplify the process of deploying and serving machine learning models, enabling you to harness the power of your models in real-world applications with ease. ","version":"Next","tagName":"h3"},{"title":"Serving a Model via HTTP","type":0,"sectionRef":"#","url":"/docs/serving-models/serving-a-model-with-http","content":"Serving a Model via HTTP Serving your machine learning model via HTTP in Semantix ML Hub is a streamlined process that allows you to deploy your models quickly and make predictions accessible through HTTP requests. Follow these steps to serve a model: Access Inference Servers Page: Navigate to the Inference Servers page within Semantix ML Hub. Add Inference Server: Click on the &quot;Add Inference Server&quot; button to initiate the model serving setup. Define Model Name: Provide a unique and descriptive name for the particular model you wish to serve. This identifier will make it easier to manage and distinguish your models. Select Model Framework: Choose the appropriate model framework from the available options. Semantix ML Hub supports various frameworks, including Scikit-learn, PyTorch, TensorFlow, TensorFlow Lite, Keras, and ONNX. Upload Model File: Upload the trained model file from your local computer. This file should contain the necessary model parameters and weights for inference. Configure Request Body: Define the request body that the inference server should expect when receiving HTTP requests. Configure from Features: Add the features from your feature tables. Create Inference Server: After configuring the model's settings and features, click on the &quot;Create Inference Server&quot; button to finalize the deployment process. Once you've completed these steps, your model will be served via HTTP, and you'll be ready to make predictions and perform inference by sending HTTP requests to the designated inference server. This streamlined approach to model deployment ensures that your machine learning models are readily accessible for real-world applications and integration with various services.","keywords":"","version":"Next"},{"title":"Ingesting Data with the Python SDK","type":0,"sectionRef":"#","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk","content":"","keywords":"","version":"Next"},{"title":"Installation​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#installation","content":"First install the SDK: pip install elemeno-ai-sdk  ","version":"Next","tagName":"h3"},{"title":"Creating a Client​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#creating-a-client","content":"First you will need to export an environment variable with your Semantix ML Hub Api Key: export MLHUB_API_KEY=&lt;YOUR_API_KEY&gt;  Replace YOUR_API_KEY with your actual API key from your Semantix account. If you don't have an API key, check this page. Then create a client instance: from elemeno_ai_sdk.ml.features.feature_table import FeatureTable ft = FeatureTable()  ","version":"Next","tagName":"h3"},{"title":"Configuring the schema of your feature tables​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#configuring-the-schema-of-your-feature-tables","content":"In order to use the feature store you need to define the schema of your feature tables. This is an important step to ensure your feature store is organized and your features are stored using the appropriate data type. You have the option to create the feature table schema definition via our GUI screen or via the SDK. The next steps will show how to perform this task using the SDK, if you prefer doing via GUI check this page. The first step is to create a JSON schema file. The file should look like: { &quot;name&quot;: &quot;creditcard_demo&quot;, &quot;entities&quot;: [&quot;id&quot;], &quot;schema&quot;: [ {&quot;name&quot;: &quot;v1&quot;, &quot;type&quot;: &quot;float&quot;}, {&quot;name&quot;: &quot;v2&quot;, &quot;type&quot;: &quot;float&quot;}, {&quot;name&quot;: &quot;v3&quot;, &quot;type&quot;: &quot;float&quot;}, {&quot;name&quot;: &quot;v4&quot;, &quot;type&quot;: &quot;float&quot;}, {&quot;name&quot;: &quot;class&quot;, &quot;type&quot;: &quot;int&quot;}, {&quot;name&quot;: &quot;event_timestamp&quot;, &quot;type&quot;: &quot;timestamp&quot;} ] }  Here are a few details about what is the schema file. name: This is the unique identifier of our feature table.entities: The entity identifier is required, you can have composed identifiers with multiple properties if necessary. When reading features, you will may want to use the entity identifier to filter features for specific entities.schema: This is all fields in the dataset. Adding field event_timestamp to filter features between data. Once you create your schema file you need to call the ingest schema method and create an instance of your feature table. import asyncio asyncio.run(ft.create(&quot;./fs_schema.json&quot;))  ","version":"Next","tagName":"h3"},{"title":"Ingesting a Pandas DataFrame​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#ingesting-a-pandas-dataframe","content":"The simplest way to ingest data is directly from a Pandas DataFrame: Creating DataFrame import pandas as pd credicard_demo = pd.DataFrame({ 'id': [1, 2, 3], 'v1': [0.3, 0.5, 0.93], 'v2': [0.1, 0.25, 0.29], 'v3': [0.1, 0.25, 0.29], 'v4': [0.1, 0.25, 0.29], 'class': [0, 1, 1], 'event_timestamp': ['2022-07-14 18:08:05.488248', '2022-07-14 18:08:06.581331', '2022-07-15 11:20:03.900023'] })  This will ingest the DataFrame into the feature table sepal_ft created in the previous step. from elemeno_ai_sdk.ml.features.feature_store import FeatureStore fs = FeatureStore() asyncio.run(fs.ingest('creditcard_demo', credicard_demo))  ","version":"Next","tagName":"h3"},{"title":"Ingesting from other sources​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#ingesting-from-other-sources","content":"You can also ingest data from any other source by converting it to pandas dataframe. The example below reads. from a CSV file: from elemeno_ai_sdk.ml.features.feature_store import FeatureStore data = pd.read_csv(FILE_PATH) fs = FeatureStore() asyncio.run(fs.ingest('creditcard_demo', credicard_demo))  The source CSV in this example must have columns that match the properties you defined in the schema file. ","version":"Next","tagName":"h3"},{"title":"Scheduled ingestion​","type":1,"pageTitle":"Ingesting Data with the Python SDK","url":"/docs/feature-store/ingestion-data/ingesting-data-with-python-sdk#scheduled-ingestion","content":"When integrating in production, oftentimes you will need to repeat the ingestion operation from time to time so that your feature store receives newly generated data from your sources. Our product does not offer a scheduler for your jobs via SDK, however you can use any pipeline management tool to have the job running on a cron. The data ingested in the feature store is never updated and it will be only deleted when you close your account or request a deletion via support ticket. The data in the feature tables is append-only, and there's no constraints in the ID field. You can ingest the same features, with the same entity ID value several times. But you need to make a good use of the &quot;event_timestamp&quot; field so that when you're training models you can select the period of features you want to use. During inference time, our server will always retrieve the most recent version of the feature. If there are multiple items with the same entity ID, during inference, the one with the latest &quot;event_timestamp&quot; will be used. ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}